{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model Inference & GenAI Demo\n",
                "Demonstrating the trained Survival Prediction model and the Generative AI model.\n"
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import sys\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(\"..\")\n",
                "\n",
                "from src.models.model_survival import SurvivalCNN\n",
                "from src.models.model_gen import UNetGenerator\n",
                "from src.data.dataset import TCGAPatchDataset\n",
                "\n",
                "DEVICE = torch.device(\"cpu\") # Use CPU for demo inference\n",
                "\n"
            ],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "outputs": [],
            "source": [
                "## 1. Survival Prediction (Phase 1)\n"
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Model\n",
                "model_surv = SurvivalCNN().to(DEVICE)\n",
                "ckpt_path = Path(\"../checkpoints/survival/best_model.pth\")\n",
                "\n",
                "if ckpt_path.exists():\n",
                "    model_surv.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
                "    model_surv.eval()\n",
                "    print(\"Survival Model Loaded.\")\n",
                "else:\n",
                "    print(\"Checkpoint not found. Run pipeline first.\")\n",
                "\n"
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Inference on a Sample\n",
                "ds = TCGAPatchDataset(split=\"val\", patch_dir=\"../data/processed/patches\", \n",
                "                      clinical_file=\"../data/processed/clinical_processed.csv\",\n",
                "                      manifest_file=\"../data/raw/image_manifest.csv\")\n",
                "\n",
                "if len(ds) > 0:\n",
                "    img, clinical, target = ds[0]\n",
                "    img_tensor = img.unsqueeze(0).to(DEVICE) # Add batch dim\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        risk_score = model_surv(img_tensor)\n",
                "        \n",
                "    print(f\"Predicted Risk Score: {risk_score.item():.4f}\")\n",
                "    print(f\"Actual Time: {target[0]:.1f} months, Event: {target[1]}\")\n",
                "    \n",
                "    plt.imshow(img.permute(1, 2, 0)) # CHW -> HWC\n",
                "    plt.title(f\"Risk: {risk_score.item():.2f}\")\n",
                "    plt.axis('off')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Dataset empty.\")\n",
                "\n"
            ],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "outputs": [],
            "source": [
                "## 2. Generative AI: Rewinding Disease (Phase 3)\n",
                "Translating Late Stage images to Early Stage appearance.\n"
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load GenAI Model\n",
                "gen = UNetGenerator().to(DEVICE)\n",
                "ckpt_gen_path = Path(\"../checkpoints/gen/G_L2E_epoch15.pth\") # Try to load a later epoch\n",
                "\n",
                "if not ckpt_gen_path.exists():\n",
                "    # Fallback to any saved\n",
                "    avail = list(Path(\"../checkpoints/gen\").glob(\"*.pth\"))\n",
                "    if avail:\n",
                "        ckpt_gen_path = sorted(avail)[-1]\n",
                "\n",
                "if ckpt_gen_path.exists():\n",
                "    gen.load_state_dict(torch.load(ckpt_gen_path, map_location=DEVICE))\n",
                "    gen.eval()\n",
                "    print(f\"GenAI Model Loaded from {ckpt_gen_path.name}\")\n",
                "else:\n",
                "    print(\"GenAI Checkpoint not found.\")\n",
                "\n"
            ],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize Translation\n",
                "if len(ds) > 0:\n",
                "    # Pick a random sample\n",
                "    idx = np.random.randint(0, len(ds))\n",
                "    real_img, _, _ = ds[idx]\n",
                "    \n",
                "    real_tensor = real_img.unsqueeze(0).to(DEVICE)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        fake_early = gen(real_tensor)\n",
                "        \n",
                "    # Plot Side by Side\n",
                "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
                "    \n",
                "    # Unnormalize for display if needed, but for now assuming roughly [0,1] or standard\n",
                "    # The transforms used Normalize mean/std, so we should denormalize to look good\n",
                "    def denorm(t):\n",
                "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
                "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
                "        return (t * std + mean).clamp(0, 1)\n",
                "\n",
                "    ax[0].imshow(denorm(real_img).permute(1, 2, 0))\n",
                "    ax[0].set_title(\"Input (Original)\")\n",
                "    ax[0].axis('off')\n",
                "    \n",
                "    ax[1].imshow(denorm(fake_early.squeeze()).permute(1, 2, 0))\n",
                "    ax[1].set_title(\"Generated (Early Stage)\")\n",
                "    ax[1].axis('off')\n",
                "    \n",
                "    plt.show()\n",
                "\n"
            ],
            "execution_count": null
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}